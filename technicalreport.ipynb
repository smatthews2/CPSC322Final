{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPSC322 Final Project -- UFO Sightings Dataset\n",
    "### Sebastian Matthews and Ethan France\n",
    "\n",
    "## 1. Introduction\n",
    "Having a shared interest in the idea of UFO sightings, the possibility of explaining such a phenomenon through statistical analysis was too enticing to pass up and allowed for the construction of a unique project. The dataset that we have used for our project contains over 80,000 UFO sighting reports across the world, providing a variety of descriptions pertaining to each case(e.g. datetime, city, state, country, shape, duration in seconds and hours/min, comments regarding the report, date posted, and longitude and latitude), all sourced from [Kaggle](https://www.kaggle.com/datasets/NUFORC/ufo-sightings) and in a CSV format. The second dataset that we used was information regarding weather conditions during the day of the sighting, which we assembled from [Wunderground's Historical Weather Reports](https://www.wunderground.com/history) via a Selenium-based web scraping bot, which stored data an Excel file format and was later merged into our primary dataset. Finally, the third dataset used as an input for the Selenium bot was a CSV file that contained information regarding [ICAO codes](https://github.com/ip2location/ip2location-iata-icao/blob/master/iata-icao.csv), allowing the bot to input the location into the website and retrieve the weather data. According to the graphs below, the features that were the most influential in our models were the maximum temperature and humidity for a given day."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Analysis\n",
    "Before reducing the scale of our dataset from ~80,000 entries to 3,657 samples, the UFO sightings dataset had attributes such as the date and time when a UFO sighting began; the city, state, and country where the sighting occured; the shape of the formation spotted; the duration of the encounter in seconds, hours, and minutes; comments from the witness; the date when the sighting was posted; and the latitude and longitude of the sighting's location. After sampling 1,000 random UFO sightings in the US, the nearest airport from another random selection of a given number(we chose 5 to reduce the time of data gathering)would be appended to each instance via an application of the Haversine formula via Geopandas. Then, the ICAO of the airport would be used to gather the weather data of a ten-year span(2003-2013) and be merged with the UFO data on date and airport code.\n",
    "\n",
    "The attributes that we utilized as class information were...\n",
    "- The dew point average of a given day, labeled \"dew-avg\".\n",
    "- The atmospheric pressure of a given day, labeled as \"pressure-avg\".\n",
    "- The temperature average of a given day, labeled as \"temp-avg\".\n",
    "- The average wind speed of a given day, labeled as \"wind-avg\".\n",
    "- The humidity average of a given day, labeled as \"humidity-avg\".\n",
    "- The total precipitation in inches for a given day, labeled as \"precipitation-total\".\n",
    "\n",
    "All of these attributes were continuous numerical values, which assisted in predicting whether or not a UFO sighting will occur for a given day based on weather features and location in our binary classification scenario. The expected outcome for our predictions would then be stored in a \"prediction\" column(a boolean value) within the table, telling us whether or not a UFO sighting was present. \n",
    "\n",
    "Our Naive Bayes model scored an accuracy of 77%, a precision of 4%, a recall of 19%, and had an F1 score of 6%; in comparison, our Random Forest model scored an accuracy of 95%, a precision of 25%, a recall of 3%, and an F1 score of 5%. Lastly, our KNN model scored an accuracy of 93%, a precision of 7%, a recall of 3%, and an F1 score of 4%. A high accuracy for KNN and Random Forest for this dataset is considered dubious due to the classifiers refusing to identify any UFO sightings, simply flagging the entire dataset as all falses.\n",
    "\n",
    "\n",
    "![Classifier Metrics Comparison](Classifier_comp.png)\n",
    "![F1 Classifier Comparison](f1_classifier_comp.png)\n",
    "![Frequency Chart](Feature_Importance_-_Random_Forest.png)\n",
    "![Feature Importance Chart NB](Feature_Importance_-_Naive_Bayes.png)\n",
    "![Classification Bar Graph](TPxTNxFPxFN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Classification Results\n",
    "\n",
    "The classifiers that we designed for our dataset were the Naive Bayes, KNN, Binary, and Random Forest algorithms, which were previously constructed during the course's individual programming assignments. Before a classifier would predict a UFO sighting, the specific weather attributes would be normalized and scrubbed of null values and then split the data between a training and test set. Once the classifer was trained on the dataset, it proceeded to calculate the class and feature probabilities and make predictions, comparing the predicted class outcomes to the actual results. For the Random Forest algorithm, the fit function generates a stratified test set along with N random decision trees, then selects the M most accurate trees to determine the majority vote for each node in order to produce the most accurate prediction for the provided dataset.\n",
    "\n",
    "Ultimately, we decided that the Naive Bayes was our best classifier. Given our dataset, we felt that accuracy could be a misleading statistic due to the distribution of UFO sightings and regular weather data being severely skewed in favor of no sightings. So, although it had the lowest accuracy, the Naive Bayes demonstrated the highest F1-Score and would actually produce true positives for our dataset. We felt that this was best because a high F1-Score indicates a good balance between precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Classification Web App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from MyNaiveBayesClassifier import MyNaiveBayesClassifier\n",
    "\n",
    "def read_excel(file_path):\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    data = []\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        data.append(list(row))\n",
    "    return data[1:]  # Skip the header\n",
    "\n",
    "def normalize_units(row, indices):\n",
    "    normalized_row = []\n",
    "    for i in indices:\n",
    "        value = row[i]\n",
    "        if value is None:\n",
    "            normalized_row.append(0)  # Handle missing values by setting to 0\n",
    "        elif i in range(14, 15):  # Humidity (%) Avg column\n",
    "            normalized_row.append(value / 100 if value is not None else None)\n",
    "        else:\n",
    "            normalized_row.append(value)\n",
    "    return normalized_row\n",
    "\n",
    "def load_filtered_dataset(file_path):\n",
    "    data = read_excel(file_path)\n",
    "    filtered_data = []\n",
    "    relevant_indices = [11, 14, 17, 20, 23, 26] + [-1]  # Avg value columns and label\n",
    "\n",
    "    for row in data:\n",
    "        if any(row[i] is None for i in relevant_indices):\n",
    "            continue\n",
    "\n",
    "        label = row[-1]\n",
    "        if isinstance(label, str):\n",
    "            label = label.strip().lower()\n",
    "            label = 1 if label == \"yes\" else 0 if label == \"no\" else None\n",
    "\n",
    "        if label is None or not all(isinstance(row[i], (int, float)) for i in relevant_indices[:-1]):\n",
    "            continue\n",
    "\n",
    "        normalized_row = normalize_units(row, relevant_indices[:-1])\n",
    "        filtered_data.append(normalized_row + [label])\n",
    "\n",
    "\n",
    "    features = [row[:-1] for row in filtered_data]\n",
    "    labels = [row[-1] for row in filtered_data]\n",
    "    return features, labels\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    true_positive = sum(1 for true, pred in zip(y_true, y_pred) if true == pred == 1)\n",
    "    false_positive = sum(1 for true, pred in zip(y_true, y_pred) if true == 0 and pred == 1)\n",
    "    false_negative = sum(1 for true, pred in zip(y_true, y_pred) if true == 1 and pred == 0)\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    accuracy = sum(1 for true, pred in zip(y_true, y_pred) if true == pred) / len(y_true)\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "def run_prediction_interface():\n",
    "    print(\"Welcome to the Naive Bayes Weather-UFO Prediction App\")\n",
    "    print(\"Enter the average weather data values below:\")\n",
    "\n",
    "    feature_names = [\n",
    "        \"Temperature (°F) Avg\", \"Dew Point (°F) Avg\",\n",
    "        \"Humidity (%) Avg\", \"Wind Speed (mph) Avg\", \"Pressure (in) Avg\", \"Precipitation (in) Total\"\n",
    "    ]\n",
    "\n",
    "    user_input = []\n",
    "    for feature in feature_names:\n",
    "        while True:\n",
    "            try:\n",
    "                value = float(input(f\"Enter {feature}: \"))\n",
    "                if \"Humidity\" in feature:\n",
    "                    value /= 100  # Normalize humidity input\n",
    "                user_input.append(value)\n",
    "                break\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter a numerical value.\")\n",
    "\n",
    "    print(\"\\nProcessing your input...\")\n",
    "\n",
    "    try:\n",
    "        # Load dataset and train model\n",
    "        file_path = 'merged_weather_ufo.xlsx'\n",
    "        features, labels = load_filtered_dataset(file_path)\n",
    "        X_train, y_train, _, _ = split_data(features, labels)\n",
    "\n",
    "        nb_classifier = MyNaiveBayesClassifier()\n",
    "        nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "        # Predict\n",
    "        prediction = nb_classifier.predict([user_input])[0]\n",
    "        result = \"likely\" if prediction == 1 else \"unlikely\"\n",
    "        print(f\"\\nPrediction: It is {result} that a UFO sighting will occur based on the provided weather data.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_prediction_interface()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Conclusion\n",
    "\n",
    "According to our analysis, there is no strong correlation between weather data and UFO sightings from our dataset; the likelihood of a sighting, which is already rare, also gets heavily skewed depending on airport selection and the size of weather report data. A “run” with 100 airports providing data provides a greater fidelity to our classification results than a “run” with only 5 airports. Therefore, we cannot predict with any certainty if a UFO will be spotted based on the weather. The way that we evaluated our classifiers' predictive ability was by paying close attention to F1 score, as \n",
    "The inherit challenges with the dataset came with the size of the charts and the manual assembly of weather data, along with the reduced correlation due to weather data and UFO sightings being separate phenomena that are fairly independent from one another. Nevertheless, the Naive Bayes classifier performed fairly well given the circumstances, properly identifying UFO sightings for seven days, and would have easily performed better when given data related to movie/media releases featuring aliens as the spike in sightings skyrocketed during the 90s according to exploratory data analysis. Further coupling such an acknowledgement with an identification of the day of the week of a sighting would also assist in explaining what contributes to an increased likelihood of experiencing alien encounters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Acknowledgements\n",
    "Historic weather data sourced from [Wunderground](https://www.wunderground.com/history).\n",
    "<br>\n",
    "Project idea inspired by Bilal Ali Shah's [article on Medium](https://medium.com/@24020041/ufo-dataset-predicting-ufo-sightings-in-the-us-7539c95e75a8).\n",
    "<br>\n",
    "[Notes on Statistics with R (SwR)](https://bookdown.org/pbaumgartner/swr-harris/10-logistic-regression.html).\n",
    "<br>\n",
    "[ChatGPT](https://chatgpt.com/) was utilized for cleaning up visualizations and troubleshooting error messages."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
