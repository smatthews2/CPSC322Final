{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> UFOs and the Weather: A Technical Report\n",
    "\n",
    "## <center> Sebastion Matthews, Ethan France\n",
    "\n",
    "### <center> CPSC 322, Fall 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'module' object is not callable. Did you mean: 'MyKNNClassifier.MyKNNClassifier(...)'?\n"
     ]
    }
   ],
   "source": [
    "import openpyxl\n",
    "import math\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Import classifiers\n",
    "from MyKNNClassifier import MyKNNClassifier\n",
    "from MyNaiveBayesClassifier import MyNaiveBayesClassifier\n",
    "from MyRandomForestClassifier import MyRandomForestClassifier\n",
    "\n",
    "# Define utility functions\n",
    "def read_excel(file_path):\n",
    "    workbook = openpyxl.load_workbook(file_path)\n",
    "    sheet = workbook.active\n",
    "    data = []\n",
    "    for row in sheet.iter_rows(values_only=True):\n",
    "        data.append(list(row))\n",
    "    return data[1:]  # Skip the header\n",
    "\n",
    "def normalize_units(row, indices):\n",
    "    normalized_row = []\n",
    "    for i in indices:\n",
    "        value = row[i]\n",
    "        if i in range(13, 16):\n",
    "            normalized_row.append(value / 100 if value is not None else None)\n",
    "        else:\n",
    "            normalized_row.append(value)\n",
    "    return normalized_row\n",
    "\n",
    "def load_filtered_dataset(file_path):\n",
    "    data = read_excel(file_path)\n",
    "    filtered_data = []\n",
    "    relevant_indices = list(range(10, 26)) + [-1]\n",
    "\n",
    "    for row in data:\n",
    "        if any(row[i] is None for i in relevant_indices):\n",
    "            continue\n",
    "\n",
    "        label = row[-1]\n",
    "        if isinstance(label, str):\n",
    "            label = label.strip().lower()\n",
    "            label = 1 if label == \"yes\" else 0 if label == \"no\" else None\n",
    "        \n",
    "        if label is None or not all(isinstance(row[i], (int, float)) for i in relevant_indices[:-1]):\n",
    "            continue\n",
    "\n",
    "        normalized_row = normalize_units(row, relevant_indices[:-1])\n",
    "        filtered_data.append(normalized_row + [label])\n",
    "\n",
    "    if not filtered_data:\n",
    "        raise ValueError(\"No valid rows found in the dataset. Please check the data and column indices.\")\n",
    "\n",
    "    features = [row[:-1] for row in filtered_data]\n",
    "    labels = [row[-1] for row in filtered_data]\n",
    "    return features, labels\n",
    "\n",
    "def split_data(X, y, test_ratio=0.2):\n",
    "    combined = list(zip(X, y))\n",
    "    random.shuffle(combined)\n",
    "    split_idx = int(len(combined) * (1 - test_ratio))\n",
    "    train_set, test_set = combined[:split_idx], combined[split_idx:]\n",
    "    return (\n",
    "        [x for x, _ in train_set], [y for _, y in train_set],\n",
    "        [x for x, _ in test_set], [y for _, y in test_set]\n",
    "    )\n",
    "\n",
    "def calculate_metrics(y_true, y_pred):\n",
    "    true_positive = sum(1 for true, pred in zip(y_true, y_pred) if true == pred == 1)\n",
    "    false_positive = sum(1 for true, pred in zip(y_true, y_pred) if true == 0 and pred == 1)\n",
    "    false_negative = sum(1 for true, pred in zip(y_true, y_pred) if true == 1 and pred == 0)\n",
    "\n",
    "    precision = true_positive / (true_positive + false_positive) if (true_positive + false_positive) > 0 else 0\n",
    "    recall = true_positive / (true_positive + false_negative) if (true_positive + false_negative) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "\n",
    "    accuracy = sum(1 for true, pred in zip(y_true, y_pred) if true == pred) / len(y_true)\n",
    "    return accuracy, precision, recall, f1_score\n",
    "\n",
    "# Main logic for the notebook\n",
    "def run_classifiers(file_path):\n",
    "    features, labels = load_filtered_dataset(file_path)\n",
    "    X_train, y_train, X_test, y_test = split_data(features, labels)\n",
    "\n",
    "    metrics = {}\n",
    "\n",
    "    # Run KNN\n",
    "    knn_classifier = MyKNNClassifier(k=5)\n",
    "    knn_classifier.fit(X_train, y_train)\n",
    "    knn_predictions = knn_classifier.predict(X_test)\n",
    "    metrics[\"KNN\"] = calculate_metrics(y_test, knn_predictions)\n",
    "\n",
    "    # Run Naive Bayes\n",
    "    nb_classifier = MyNaiveBayesClassifier()\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    nb_predictions = nb_classifier.predict(X_test)\n",
    "    metrics[\"Naive Bayes\"] = calculate_metrics(y_test, nb_predictions)\n",
    "\n",
    "    # Run Random Forest\n",
    "    rf_classifier = MyRandomForestClassifier(n_trees=10, m_trees=3, f_features=2)\n",
    "    rf_classifier.fit(X_train, y_train)\n",
    "    rf_predictions = rf_classifier.predict(X_test)\n",
    "    metrics[\"Random Forest\"] = calculate_metrics(y_test, rf_predictions)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "def visualize_metrics(metrics):\n",
    "    classifiers = list(metrics.keys())\n",
    "    accuracy = [metrics[clf][0] for clf in classifiers]\n",
    "    precision = [metrics[clf][1] for clf in classifiers]\n",
    "    recall = [metrics[clf][2] for clf in classifiers]\n",
    "    f1_scores = [metrics[clf][3] for clf in classifiers]\n",
    "\n",
    "    x = np.arange(len(classifiers))\n",
    "    width = 0.2\n",
    "\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    plt.bar(x - width, accuracy, width, label=\"Accuracy\", color=\"skyblue\")\n",
    "    plt.bar(x, precision, width, label=\"Precision\", color=\"orange\")\n",
    "    plt.bar(x + width, recall, width, label=\"Recall\", color=\"green\")\n",
    "\n",
    "    plt.xticks(x, classifiers)\n",
    "    plt.ylabel(\"Score\")\n",
    "    plt.title(\"Classifier Metrics Comparison\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.bar(classifiers, f1_scores, color=\"purple\")\n",
    "    plt.ylabel(\"F1 Score\")\n",
    "    plt.title(\"F1 Score Comparison\")\n",
    "    plt.show()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        file_path = 'merged_weather_ufo.xlsx'\n",
    "        metrics = run_classifiers(file_path)\n",
    "        visualize_metrics(metrics)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
